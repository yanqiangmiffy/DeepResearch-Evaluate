Parameter Efficient Fine-Tuning（PEFT）方法综述与比较
1. PEFT 核心思想
PEFT（Parameter-Efficient Fine-Tuning）是一种针对大型预训练模型的微调技术，通过仅调整少量参数（而非全量参数）适应新任务，从而降低计算和存储成本，同时保持模型性能 。

2. 主流方法对比
方法	核心原理	参数效率	适用场景	优缺点
LoRA	通过引入低秩矩阵（由两个小矩阵相乘得到）调整预训练权重，仅更新低秩矩阵参数	高	大语言模型（如GPT、T5）的微调	✔️ 高效调整Q/V层参数；
❌ 低秩矩阵秩的选择影响性能（通常rank=4或8）
Adapter	在Transformer层间插入轻量级适配器模块（含输入/输出层、非线性激活），仅训练适配器参数	中	需要稳定保留原模型参数的任务（如多任务学习）	✔️ 模块化设计便于扩展；
❌ 增加模型深度可能影响推理速度
IA3	通过注入可训练向量到注意力机制和前馈网络，调整激活值（如缩放因子）	极高	需要极低参数量的场景（如资源受限设备）	✔️ 参数量极少；
❌ 可能牺牲部分任务适应性
3. 方法详解
3.1 LoRA（Low-Rank Adaptation）
原理：在预训练权重矩阵（如注意力层的Q/V矩阵）上添加低秩分解矩阵，仅训练分解后的子矩阵 。
参数调整：
目标模块：通常选择Q（Query）和V（Value）层，因其直接影响注意力权重和输出表示 。
Rank选择：经验值4或8，平衡性能与计算开销 。
优势：
参数效率高（仅调整0.1%-1%参数）；
支持多任务共享同一预训练模型。
3.2 Adapter Tuning
结构：
输入层 → 下投影层（降维）→ 非线性激活 → 上投影层（恢复维度）。
通常插入Transformer的FFN（前馈网络）层之间 。
训练流程：
冻结预训练模型参数；
仅训练适配器模块和任务特定层（如分类头）。
3.3 IA3（Inhibit and Amplify Adaptive Elements）
原理：通过可训练向量对注意力机制的Key/Value和前馈网络的中间激活进行缩放 。
特点：
参数量极低（仅需约0.01%参数）；
适用于需要快速部署的场景（如边缘计算）。
4. 性能与适用性总结
维度	LoRA	Adapter	IA3
参数量	低（~0.1%-1%）	中（~1%-5%）	极低（~0.01%）
训练速度	较快	中等	最快
任务适应性	高	高	中等
部署复杂度	低（仅合并矩阵）	中（增加模块深度）	低（仅注入向量）
5. 实践建议
资源充足场景：优先选择 LoRA，平衡效率与性能 ；
多任务学习：考虑 Adapter，避免任务间干扰 ；
资源受限场景：尝试 IA3，以极低参数量快速适配。
⚠️ 注：IA3的详细实现未在提供的搜索结果中体现，需结合其他文献或实践验证。